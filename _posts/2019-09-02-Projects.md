---
layout: post
title: Thesis projects
date:   2019-09-03
author: Katia
categories: Info
mathjax: true
---

Hello everyone,

NLP researchers at UvA have proposed some exciting thesis projects for you! You can find them below. If you are interested in any of the projects, please contact the prospective supervisor directly.


### Probing for typological properties in multilingual word and sentence representations 

Supervisor: [Ekaterina Shutova](mailto:e.shutova@uva.nl) 

Collaborators: Douwe Kiela (Facebook AI Research)

#### Description

Languages may share universal features at a deep, abstract level, but the structures found in real-world, surface-level natural language vary significantly. This variation makes it challenging to transfer NLP models across languages or to develop systems that apply to a wide range of languages. As a consequence, the availability of NLP technology is limited to a handful of resource-rich languages, leaving many other languages behind. Understanding linguistic variation in a systematic way is crucial for the development of effective multilingual NLP applications, thus making NLP technology more accessible globally. 

In recent years, much NLP research has focused on the development of multilingual models, typically based on multilingual joint learning or zero-shot transfer learning across languages. Much of this research has utilized multilingual word or sentence representations, that project words or sentences in multiple languages into a shared multilingual semantic space. Such models abstract over language-specific features and represent words and sentences from multiple languages in a language-agnostic manner, such that words or sentences with similar meanings (regardless of an actual language) obtain similar representations. While this work has met with success, enabling effective model transfer across languages, little is known about the linguistic properties of individual languages that such representations encode. The goal of this project is to investigate to what extent multilingual word and sentence representations capture the patterns of cross-lingual similarity and variation. We will use techniques from the rapidly growing field of interpretation of neural networks (e.g. Tenney et al. 2019) to design methods for probing state-of-the-art multilingual contextualised word representations and sentence encoders, such as LASER (Artexte and Schwenk, 2018), multilingual BERT (Devlin et al., 2019) or XLM (Lample and Conneau, 2019), for a range of language characteristics. We will thus investigate to what extent the above models encode typological features pertaining to syntactic and semantic structure, how these are represented within the network and generalised across language families. We will also look at whether these models can be used to automatically induce the patterns of linguistic variation across language families.

This is an ambitious project, suitable for students with a background and interest in machine learning and keen to conduct novel research. We hope that it would lead to a publication.

#### What are our expectations of the student?

- Independent and proactive attitude and an interest in artificial intelligence
- Solid maths background: calculus, linear algebra, probability and statistics
- Advanced programming skills (algorithms and data structures; ideally experience with Pytorch or other deep learning libraries)
- Knowledge and skill in developing and applying machine learning algorithms (particularly, interest and experience in deep learning) 
- Good familiarity with and experience in NLP; but don’t worry we will help you to fill in the gaps.

#### Further reading:

Edoardo Ponti, Helen O'Horan, Yevgeni Berzak, Ivan Vulic, Roi Reichart, Thierry Poibeau, Ekaterina Shutova, Anna Korhonen. 2018. Modeling Language Variation and Universals: A Survey on Typological Linguistics for Natural Language Processing.  In arXiv e-prints, abs/1807.00914. 

Mikel Artetxe and Holger Schwenk. 2018. Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond. ArXiv.

Tal Schuster, Ori Ram, Regina Barzilay, Amir Globerson. Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing. In Proceedings of NAACL 2019.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language understanding. In Proceedings of NAACL 2019.

Guillaume Lample and Alexis Conneau. 2019. Cross-lingual Language Model Pretraining. ArXiv.

Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, and Ellie Pavlick. 2019. What do you learn from context? Probing for sentence structure in contextualized word representations. Proceedings of ICLR 2019.


### Abusive language detection in conversation

Supervisor: [Ekaterina Shutova](mailto:e.shutova@uva.nl)

Collaborators: Helen Yannakoudakis (University of Cambridge) and Pushkar Mishra (Facebook AI Research)

#### Description

With the advent of social media, aggressive and abusive behaviour online has become one of its prominent features. The undesirable psychological effects of online abuse on individuals make it an important societal problem of our time. The term abuse encompasses hate speech, racism, sexism, derogatory language, personal attacks and cyber­bullying. In recent years, a new research effort on automated abuse detection has sprung up in the field of NLP. The community has experimented with a range of techniques such as recurrent and convolutional neural networks, character-based models and graph-based methods capturing the properties of the social network. While these methods have achieved substantial success, they have an important limitation in that they focus on modeling the linguistic properties of comments in isolation from other comments. Abuse is, however, inherently a situational and contextual phenomenon --- it can only be interpreted as part of a wider conversation between users on the Internet. This means that individual comments can be difficult to classify without modeling their respective contexts. For instance, Mishra et al. (2018) have pointed out that many comments in widely-used Twitter datasets do not contain sufficient lexical or semantic information to detect abuse even in principle and techniques for modeling discourse and elements of pragmatics are needed. In this project, we will address this problem and develop novel abuse detection methods that capture the history of the conversation and the behavior of the users as it develops over time. We will use techniques from the domain of discourse and dialogue modelling (such as memory networks, recurrent neural networks with attention etc), as well as graph-based methods (such as graph convolutional networks), to model interactions between the users. In addition, we will also incorporate insights from experimental research on conversational behaviour among individuals and groups in fields such as psychology and linguistics.

This is an ambitious project, suitable for students with a background and interest in machine learning and keen to conduct novel research. We hope that it would lead to a publication.

#### What are our expectations of the student?

- Independent and proactive attitude and an interest in artificial intelligence
- Solid maths background: calculus, linear algebra, probability and statistics
- Advanced programming skills (algorithms and data structures; ideally experience with Pytorch or other deep learning libraries)
- Knowledge and skill in developing and applying machine learning algorithms (particularly, interest and experience in deep learning) 
- Good familiarity with and experience in NLP; but don’t worry we will help you to fill in the gaps.

#### Further reading:

P. Mishra, M. Del Tredici, H. Yannakoudakis, and E. Shutova. Author profiling for abuse detection. In Proceedings of COLING 2018, pages 1088–1098. ACL, 2018. 

P. Mishra, E. Shutova, and H. Yannakoudakis. Neural character-­based composition models for abuse detection. In Proceedings of the EMNLP Workshop on Abusive Language Online, ACL, 2018. 

J. Pavlopoulos, P. Malakasiotis, and I. Androutsopoulos. Deep learning for user comment moderation. In Proceedings of the 1st Workshop on Abusive Language Online, pages 25–35. ACL, 2017.

Z. Waseem, T. Davidson, D. Warmsley, and I. Weber. Understanding abuse: A typology of abusive language detection subtasks. In Proceedings of the 1st Workshop on Abusive Language Online, pages 78–84. ACL, 2017. 

Justine Zhang, Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil, Lucas Dixon, Yiqing Hua, Nithum Thain, Dario Taraborelli. 2018. Conversations Gone Awry: Detecting Early Signs of Conversational Failure. In Proceedings of ACL 2018.

Pushkar Mishra, Helen Yannakoudakis and Ekaterina Shutova. 2019. Tackling Online Abuse: A Survey of Automated Abuse Detection Methods. In ArXiv e-prints.

Pushkar Mishra, Marco del Tredici, Helen Yannakoudakis and Ekaterina Shutova. 2019. Abusive language detection with graph convolutional networks. In Proceedings of NAACL-HLT 2019. Minneapolis, USA.


### Modelling the structure and linguistic behaviour of online communities to detect misinformation

Supervisor: [Ekaterina Shutova](mailto:e.shutova@uva.nl)

Collaborators: Helen Yannakoudakis (University of Cambridge) and Pushkar Mishra (Facebook AI Research)

#### Description

The spread of misinformation online leads to undesirable consequences in many areas of societal life, most notably visible in the political arena and healthcare. Misinformation appears in many forms, from content that is outright false (known as “fake news”) to propaganda and highly opinionated content, presenting a biased view of the world or carefully selecting facts to reinforce a particular perspective. Recent years have seen a growing interest in automatic detection of false and misleading content in the field of NLP, with researchers typically defining the problem as a classification of articles as misleading or not. The majority of existing approaches in this area have focused on modelling the structure, style and content of the online documents and comments, paying less attention to ways in which misleading content is propagated online. This project aims to advance this line of research by modelling the structure of online communities within which misinformation spreads and the linguistic behavior of the users in these communities, which is indicative of their stance on a given issue. We will experiment with state-of-the-art methods for representation learning on graphs and networks, such as graph convolutional networks (Kipf and Welling, 2017) and GraphSAGE (Hamilton et al., 2017) among others.

This is an ambitious project, suitable for students with a background and interest in machine learning and keen to conduct novel research. We hope that it would lead to a publication.

#### What are our expectations of the student?

- Independent and proactive attitude and an interest in artificial intelligence
- Solid maths background: calculus, linear algebra, probability and statistics
- Advanced programming skills (algorithms and data structures; ideally experience with Pytorch or other deep learning libraries)
- Knowledge and skill in developing and applying machine learning algorithms (particularly, interest and experience in deep learning) 
- Good familiarity with and experience in NLP; but don’t worry we will help you to fill in the gaps.

#### Further reading:

Thomas N. Kipf and Max Welling. 2017. Semi-supervised classification with graph convolutional
networks. In Proceedings of the 5th International Conference on Learning Representations, ICLR 2017.

William L. Hamilton, Rex Ying and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In Proceedings of NIPS 2017.

Pushkar Mishra, Marco del Tredici, Helen Yannakoudakis and Ekaterina Shutova. 2019. Abusive language detection with graph convolutional networks. In Proceedings of NAACL-HLT 2019. Minneapolis, USA.

K. Xu, W. Hu, J. Leskovec, S. Jegelka. How Powerful Are Graph Neural Networks? In Proceedings of ICLR, 2019.

Fatemeh Torabi Asr, Maite Taboada. 2019. Big Data and quality data for fake news and misinformation detection. Big Data and Society.




### Lexical ambiguity and polysemy with density matrices

Supervisors: Martha Lewis (ILLC) and [Ekaterina Shutova](mailto:e.shutova@uva.nl) (ILLC)

#### Description

Polysemy is the phenomenon that words adopt different meanings according to their contexts of use. This can range from clear-cut ambiguity such as 'diamond' with the meaning 'gemstone' or 'shape' to more subtle polysemous meaning such as 'window' in 'Marcelle broke the window' (the glass) or 'The bird flew out of the window' (the opening). Approaches to modelling polysemy in distributional semantics include building one representation that can represent all senses at once, or alternatively, representing different senses as separate vectors.

A recent extension to standard vector-based semantics uses the notion of a density matrix from quantum theory to encode a statistical ensemble of vectors. This has been posited to model lexical ambiguity (Piedeleu et al., 2016) and entailment (Sadrzadeh et al., 2018, Bankova et al., 2019, Lewis 2019). Since density matrices can encode a number of vectors within one representation, they form a middle ground between the two approaches described above.

Furthermore, density matrix representations can be understood within a tensor-based compositional distributional semantic model (Coecke et al., 2010, Baroni and Zamparelli 2010). The resolution of ambiguous terms in context can therefore be realised within the composition of strings of words into phrases.

This project will investigate different ways of building density matrix representations of words, including designing novel neural network architectures inspired by the density matrix approach. Ways of composing the matrices to form phrase and sentence representations will also be a topic of research. Comparisons will be made with recent work on contextualised word representations (Peters et al, 2018, Devlin et al, 2019), and the project would contribute to this line of research by designing new models.  The representations and composition methods will be assessed against datasets that require disambiguation, such as for Mitchell and Lapata (2008), Grefenstette and Sadrzadeh (2011), or WiC: The Word-in-Context Dataset (https://pilehvar.github.io/).

Following on from this, the use of density matrices to encode polysemy can be investigated within the context of metaphor. Metaphor can be viewed as a type of polysemy (Peters and Peters, 2000), and the effectiveness of disambiguating literal and metaphorical senses of a word has been shown in Gutierrez et al., (2016). This part of the project will investigate the effectiveness of using density matrix representations in metaphor identification and/or interpretation. 

This is an ambitious project, suitable for students with a background and interest in mathematics and machine learning and keen to conduct novel research. We hope that it would lead to a publication.

#### What are our expectations of the student?

- Independent and proactive attitude and an interest in artificial intelligence
- Solid maths background: calculus, linear algebra, probability and statistics
- Advanced programming skills (algorithms and data structures; ideally experience with Pytorch or other deep learning libraries)
- Knowledge and skill in developing and applying machine learning algorithms (particularly, interest and experience in deep learning) 
- Good familiarity with and experience in NLP; but don’t worry we will help you to fill in the gaps.


#### Further reading:

Bankova, D., Coecke, B., Lewis, M., & Marsden, D. (2019). Graded hyponymy for compositional distributional semantics. Journal of Language Modelling, 6(2), 225-260. http://jlm.ipipan.waw.pl/index.php/JLM/article/view/230

Baroni, M., & Zamparelli, R. (2010). Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (pp. 1183-1193). Association for Computational Linguistics. https://www.aclweb.org/anthology/D10-1115

Coecke, B., Sadrzadeh, M., & Clark, S. (2010). Mathematical Foundations for a Compositional Distributed Model of Meaning. Lambek Festschrift, Linguistic Analysis, vol. 36. https://arxiv.org/abs/1003.4394

Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019, June). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 4171-4186). https://arxiv.org/abs/1810.04805

Grefenstette, E., & Sadrzadeh, M. (2011, July). Experimental support for a categorical compositional distributional model of meaning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (pp. 1394-1404). Association for Computational Linguistics. https://www.aclweb.org/anthology/D11-1129

Gutierrez, E. D., Shutova, E., Marghetis, T., & Bergen, B. (2016, August). Literal and metaphorical senses in compositional distributional semantic models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 183-193). https://www.aclweb.org/anthology/P16-1018

Lewis, M., (2019). Compositional Hyponymy with Positive Operators. To appear at RANLP 2019. (preprint available on request)

Mitchell, J., & Lapata, M. (2008, June). Vector-based models of semantic composition. In proceedings of ACL-08: HLT (pp. 236-244). https://www.aclweb.org/anthology/P08-1028

Peters, W., & Peters, I. (2000, May). Lexicalised Systematic Polysemy in WordNet. In LREC. http://www.lrec-conf.org/proceedings/lrec2000/pdf/148.pdf

Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. In Proceedings of NAACL-HLT (pp. 2227-2237). https://arxiv.org/abs/1802.05365

Piedeleu, R., Kartsaklis, D., Coecke, B., & Sadrzadeh, M. (2015). Open System Categorical Quantum Semantics in Natural Language Processing. In 6th Conference on Algebra and Coalgebra in Computer Science (CALCO 2015). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik. https://arxiv.org/abs/1502.00831

Sadrzadeh, M., Kartsaklis, D., & Balkır, E. (2018). Sentence entailment in compositional distributional semantics. Annals of Mathematics and Artificial Intelligence, 82(4), 189-218.


### Modelling the language of populism

Supervisor: [Ekaterina Shutova](mailto:e.shutova@uva.nl) 

Collaborators: David Abadi (UvA Department of Psychology)

#### Description

TBA


###  Citation embeddings
 
Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl) and [Nees J. van Eck]( https://www.cwts.nl/people/nees-jan-van-eck) (CWTS, Leiden University)
 
#### Description
 
Scientific publications contain large amounts of citations to other publications. Citations occur within the text of publications, in sentences or paragraphs named citation contexts. In this project, we will consider the citation contexts from where a given publication is cited as a timed stream. We will thus explore the following questions: A) can we embed citations into a low-dimensional space using their citation contexts? Which embedding method is most suited for the task (e.g., Word2Vec, GloVe, BERT)? How is the resulting space configured? For example, can we cluster citations by their purpose, by the contribution of the cited paper (e.g., a method or a claim) or by where they occur in the text (e.g., section)? B) How is the citation embedding of highly-cited papers changing over time, as the paper gets older? C) Are citation embeddings sensitive to different academic disciplines? D) Are citation embeddings predictive of future citations? Understanding citation contexts is crucial to improve scholarly information retrieval and for the automation of science. It can also be relevant to improve existing visualization tools to map science.
For this project, you will use data from the full-text of all Elsevier publications (>10M) and the PubMed Open Access collection (>2M). The project is done in collaboration with the [Centre for Science and Technology Studies (CWTS), Leiden University](https://www.cwts.nl), which provides access to data and expertise in science studies.
 
#### Further reading:
 
Berger, Matthew, Katherine McDonough, and Lee M. Seversky. 2017. “Cite2vec: Citation-Driven Document Exploration via Word Embeddings.”  https://doi.org/10.1109/TVCG.2016.2598667.
He, Jiangen, and Chaomei Chen. 2017. “Understanding the Changing Roles of Scientific Publications via Citation Embeddings” https://arxiv.org/abs/1711.05822.
———. 2018. “Temporal Representations of Citations for Understanding the Changing Roles of Scientific Publications.” https://doi.org/10.3389/frma.2018.00027.
Small, Henry, Kevin W. Boyack, and Richard Klavans. 2019. “Citations and Certainty: A New Interpretation of Citation Counts.” https://doi.org/10.1007/s11192-019-03016-z.
Tshitoyan, Vahe, John Dagdelen, Leigh Weston, Alexander Dunn, Ziqin Rong, Olga Kononova, Kristin A. Persson, Gerbrand Ceder, and Anubhav Jain. 2019. “Unsupervised Word Embeddings Capture Latent Knowledge from Materials Science Literature.” https://doi.org/10.1038/s41586-019-1335-8.
 
###  Towards machine-generated review articles
 
Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl)
 
Review articles play a crucial role in summarizing and consolidating previous scientific results. Given the growing number of scientific articles being published every year, their importance is growing as well. Systematic review articles are particularly vital in medicine, in order to consolidate trials on a given topic. Unfortunately, writing a review article is an increasingly prohibitive task for researchers, in terms of time and effort involved. AI can play a significant role into aiding researchers performing that task and, in the limit, fully automating it. In this project, we will explore (some of) the following: A) learn to rank literature which made it into a review article. This covers the task of selecting literature for a review article. B) Explore or devise an extractive summarization baseline for the task of assembling a set of sentences or paragraphs from the selected articles, which are good candidates to be paraphrased into a review article. Extractive summarization, as the name suggests, uses chunks of text taken from the articles to be summarized. C) Explore or devise an abstractive summarization method to summarize a set of articles using new, machine-generated text.
For this project, you will use data from the full-text of all Elsevier publications (>10M) and the PubMed Open Access collection (>2M). The project is done in collaboration with the [Centre for Science and Technology Studies (CWTS), Leiden University](https://www.cwts.nl), which provides access to data and expertise in science studies.
 
#### Further reading:
 
Belter, Christopher W. 2016. “Citation Analysis as a Literature Search Method for Systematic Reviews.” http://onlinelibrary.wiley.com/doi/10.1002/asi.23605/pdf.
Cohan, Arman, and Nazli Goharian. 2017. “Scientific Document Summarization via Citation Contextualization and Scientific Discourse.” https://doi.org/10.1007/s00799-017-0216-8.
Conroy, John M., and Sashka T. Davis. 2017. “Section Mixture Models for Scientific Document Summarization.” https://doi.org/10.1007/s00799-017-0218-6.
Yasunaga, Michihiro, Rui Zhang, Kshitijh Meelu, Ayush Pareek, Krishnan Srinivasan, and Dragomir Radev. 2017. “Graph-Based Neural Multi-Document Summarization.” https://arxiv.org/abs/1706.06681.
Keneshloo, Yaser, Naren Ramakrishnan, and Chandan K. Reddy. 2018. “Deep Transfer Reinforcement Learning for Text Summarization.” http://arxiv.org/abs/1810.06667.
Merity, Stephen, Caiming Xiong, James Bradbury, and Richard Socher. 2016. “Pointer Sentinel Mixture Models.” https://arxiv.org/abs/1609.07843.
O’Mara-Eves, Alison, James Thomas, John McNaught, Makoto Miwa, and Sophia Ananiadou. 2015. “Using Text Mining for Study Identification in Systematic Reviews: A Systematic Review of Current Approaches.” https://doi.org/10.1186/2046-4053-4-5.
Park, Donghyeon, Yonghwa Choi, Daehan Kim, Minhwan Yu, Seongsoon Kim, and Jaewoo Kang. 2019. “Can Machines Learn to Comprehend Scientific Literature?” https://doi.org/10.1109/ACCESS.2019.2891666.
Parveen, Daraksha, Mohsen Mesgar, and Michael Strube. 2016. “Generating Coherent Summaries of Scientific Articles Using Coherence Patterns.” https://www.aclweb.org/anthology/D/D16/D16-1074.pdf.
Tshitoyan, Vahe, John Dagdelen, Leigh Weston, Alexander Dunn, Ziqin Rong, Olga Kononova, Kristin A. Persson, Gerbrand Ceder, and Anubhav Jain. 2019. “Unsupervised Word Embeddings Capture Latent Knowledge from Materials Science Literature.” https://doi.org/10.1038/s41586-019-1335-8.
 
###  Predicting citations in Wikipedia
 
Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl), [Ludo Waltman]( https://www.cwts.nl/people/ludo-waltman) (CWTS, Leiden University) and [Bob West]( https://dlab.epfl.ch/people/west/) (EPFL)
 
#### Description
 
Wikipedia is one of the main access points to scientific knowledge for the general public. Educators, students, professionals use it regularly to check facts and get insights. Yet little is known on which scientific publications are referred from Wikipedia, and thus used to support the claims it contains. In this project, we will first consider citations with identifiers from Wikipedia (this data is already made available) and link them with large-scale citation indexes (e.g., Microsoft Academic). The two key questions we will need to answer are: which publications make it into Wikipedia (e.g., highly cited ones or recent ones?) and when are they added (how long after publication?). This analysis will be performed by research field. Secondly, we will improve on existing art to detect when a citation might be needed from a Wikipedia statement, and propose a list of possible candidates for a new citation. This work will be of great value to Wikipedia editors and can impact the contents of the encyclopedia by growing and de-biasing the evidence base it relies upon.
For this project, you will use data from Wikipedia and Microsoft Academic. The project is done in collaboration with the [Centre for Science and Technology Studies (CWTS), Leiden University](https://www.cwts.nl), which provides access to citation data and expertise in science studies, and with the [Data Science Laboratory of the EPFL](https://dlab.epfl.ch), which provides Wikipedia data and expertise. The project will be conducted in coordination with [Wikimedia Foundation Research](https://research.wikimedia.org).
 
#### Further reading:
 
Lemmerich, Florian, Diego Sáez-Trumper, Robert West, and Leila Zia. 2018. “Why the World Reads Wikipedia: Beyond English Speakers.” http://arxiv.org/abs/1812.00474.
Redi, Miriam, Besnik Fetahu, Jonathan Morgan, and Dario Taraborelli. 2019. “Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia’s Verifiability.” http://arxiv.org/abs/1902.11116.
Thompson, Neil, and Douglas Hanley. 2017. “Science Is Shaped by Wikipedia: Evidence from a Randomized Control Trial.” https://doi.org/10.2139/ssrn.3039505.

###  Optical Character Recognition (OCR) unsupervised post-correction

Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl), Kasra Hosseini and Mariona Coll Ardanuy (The Alan Turing Institute)

#### Description

Increasing amounts of historical texts are being digitized and OCRed, that is to say their text extracted from the images. Notable examples include newspapers and books. OCR is an error-prone procedure, in part due to the challenges of historical texts, such as lack of vocabulary uniformity. Traditionally, OCRed texts have been post-corrected using complex sets of rules or by hand, or not at all. More recently, promising results from state-of-the-art deep learning language models encourage the exploration of fully unsupervised OCRed text post-correction: by leveraging a trained language model, the post-correction can be performed by suitably consolidating the original vocabulary. Positive results would have a large impact on the accessibility of historical texts in the digital humanities and heritage sectors. The project aims at exploring suitable language models for the task at hand (Word2Vec, GloVe, Flair, BERT and more), at devising an appropriate measure for detecting tokens with errors and at applying it for post-correcting existing texts. The project uses data (mainly 19th-century newspapers in English) and benefits from experts from the [Living with Machines project](https://www.turing.ac.uk/research/research-projects/living-machines), based the [The Alan Turing Institute](https://www.turing.ac.uk) and the [British Library](https://www.bl.uk). 

#### Further reading:

Evershed, John, and Kent Fitch. 2014. “Correcting Noisy OCR: Context Beats Confusion.” https://doi.org/10.1145/2595188.2595200.
Hakala, Kai, Aleksi Vesanto, Niko Miekka, Tapio Salakoski, and Filip Ginter. 2019. “Leveraging Text Repetitions and Denoising Autoencoders in OCR Post-Correction.” http://arxiv.org/abs/1906.10907.
Hill, Mark J, and Simon Hengchen. 2019. “Quantifying the Impact of Messy Data on Historical Text Analysis.” https://doi.org/10.1093/llc/fqz024.

###  Multi-scale dynamic topic modelling for historical newspapers

Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl) and Kasra Hosseini (The Alan Turing Institute)

#### Description

Increasing amounts of historical texts are being digitized and their texts extracted. Notable examples include newspapers and books. Detecting meaningful topics for these large text collections remains an open challenge. In particular, topics at multiple scales are necessary in order to allow for a richer exploration of these contents. Further challenges include the need to account for time, as historical collections can span decades or even centuries. The project aims at exploring a variety of unsupervised topic modelling techniques, including dynamic topic models, structured topic models and neural topic models, in order to devise and deploy a suitable topic model for a large collection of 19th-century newspapers in English. Requirements include accounting for topic change over time and for different topic scales. The project uses data and benefits from experts from the [Living with Machines project](https://www.turing.ac.uk/research/research-projects/living-machines), based the [The Alan Turing Institute](https://www.turing.ac.uk) and the [British Library](https://www.bl.uk). 

#### Further reading:

Blei, David M., and John D. Lafferty. 2006. “Dynamic Topic Models.” http://dl.acm.org/citation.cfm?id=1143859.
Blei, David M., Andrew Y. Ng, and Michael I. Jordan. 2003. “Latent Dirichlet Allocation.” http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf.
Dieng, Adji B., Francisco J. R. Ruiz, and David M. Blei. 2019a. “Topic Modeling in Embedding Spaces.” http://arxiv.org/abs/1907.04907.
———. 2019b. “The Dynamic Embedded Topic Model.” http://arxiv.org/abs/1907.05545.
Gerlach, Martin, Tiago P Peixoto, and Eduardo G Altmann. 2018. “A Network Approach to Topic Models.” https://arxiv.org/abs/1708.01677.
Roberts, Margaret E., Brandon M. Stewart, and Edoardo M. Airoldi. 2013. “A Model for Text Experimentation in the Social Sciences.” https://scholar.princeton.edu/sites/default/files/bstewart/files/stm.pdf.
Wallach, Hanna M., Iain Murray, Ruslan Salakhutdinov, and David Mimno. 2009. “Evaluation Methods for Topic Models.” http://dl.acm.org/citation.cfm?id=1553515.
Wang, Jacob Su. 2017. “Topic Modeling: A Complete Introductory Guide.” http://suwangcompling.com/wp-content/uploads/2017/04/intro_topicmodel_jsw.pdf.

###  Digital Humanities shared tasks: Semantic change and Named Entity Recognition

Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl), Kaspar Beelen and Mariona Coll Ardanuy (The Alan Turing Institute)

#### Description

In 2020, two novel NLP challenges will be released with a focus on digital humanities and historical data: Semantic change (SemEval 2020) and (multilingual) Named Entity Recognition (Clef 2020). Shared tasks are released with an annotated dataset which you can use to train and test novel models: this project thus will exclusively focus on beating the state of the art on one of the two tasks, the one you prefer. Part of the project will entail submitting to the conference and, if accepted, publish and attending in person. 
Semantic change focuses on detecting a shift in word meaning over time, a task that has attracted attention in recent years and is just starting to be applied on historical data (read: over centuries of changes, instead of years). Named Entity Recognition and Disambiguation (NERD) is a known task in NLP, where the goal is to detect mentions of named entities (e.g., persons or places) in texts, and link them to unique identifiers. NERD poses several challenges when applied to historical texts, including bad OCR quality and missing identifiers in gazetteers. Both semantic change and NERD state of the art models presently work with deep learning architectures and pre-trained language models, yet it is unknown which architecture will perform best at these challenges (it’s the first time they are proposed!)

#### Further reading:

NERD:

Coll Ardanuy, Mariona, Jürgen Knauth, Andrei Beliankou, Maarten van den Bos, and Caroline Sporleder. 2016. “Person-Centric Mining of Historical Newspaper Collections.” https://doi.org/10.1007/978-3-319-43997-6_25.
Ehrmann, Maud, Giovanni Colavizza, Yannick Rochat, and Frédéric Kaplan. 2016. “Diachronic Evaluation of NER Systems on Old Newspapers.” https://infoscience.epfl.ch/record/221391.
Shen, Yanyao, Hyokun Yun, Zachary C. Lipton, Yakov Kronrod, and Animashree Anandkumar. 2017. “Deep Active Learning for Named Entity Recognition.” http://arxiv.org/abs/1707.05928.
Won, Miguel, Patricia Murrieta-Flores, and Bruno Martins. 2018. “Ensemble Named Entity Recognition (NER): Evaluating NER Tools in the Identification of Place Names in Historical Corpora.” https://doi.org/10.3389/fdigh.2018.00002.

Semantic change:

Anderson, Ashton, Dan McFarland, and Dan Jurafsky. 2012. “Towards a Computational History of the ACL: 1980-2008.” http://dl.acm.org/citation.cfm?id=2390510.
Hamilton, William L., Jure Leskovec, and Dan Jurafsky. 2016. “Cultural Shift or Linguistic Drift? Comparing Two Computational Measures of Semantic Change.” http://arxiv.org/abs/1606.02821.
Jo, Eun Seo, and Mark Algee-Hewitt. 2018. “The Long Arc of History: Neural Network Approaches to Diachronic Linguistic Change.” https://www.jstage.jst.go.jp/article/jjadh/3/1/3_1/_article.
Kutuzov, Andrey, Lilja Øvrelid, Terrence Szymanski, and Erik Velldal. 2018. “Diachronic Word Embeddings and Semantic Shifts: A Survey.” http://arxiv.org/abs/1806.03537.
Lansdall-Welfare, Thomas, Saatviga Sudhahar, James Thompson, Justin Lewis, FindMyPast Newspaper Team, and Nello Cristianini. 2017. “Content Analysis of 150 Years of British Periodicals.” https://doi.org/10.1073/pnas.1606380114.
Rudolph, Maja, and David Blei. 2018. “Dynamic Embeddings for Language Evolution.” https://doi.org/10.1145/3178876.3185999.
Rule, Alix, Jean-Philippe Cointet, and Peter S. Bearman. 2015. “Lexical Shifts, Substantive Changes, and Continuity in State of the Union Discourse, 1790–2014.” https://doi.org/10.1073/pnas.1512221112.
Tahmasebi, Nina, Lars Borin, and Adam Jatowt. 2018. “Survey of Computational Approaches to Diachronic Conceptual Change.” http://arxiv.org/abs/1811.06278.
Tang, Xuri. 2018. “A State-of-the-Art of Semantic Change Computation.” http://arxiv.org/abs/1801.09872.

###  Transfer Learning for historical texts: Evaluating the impact of OCR and language change on the transferability of language models

Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl) and Daniel van Strien (British Library)

Pre-trained language models utilising deep learning have led to state of the art results in many NLP tasks. Compared to Word2Vec and other word embedding models, new deep learning language models, such as ULMFiT, ELMo and BERT are able to capture richer representations of language features. A major benefit of these models is that they can be trained on large corpora without supervision. These pre-trained language models have subsequently been made available for others to use. This has had the to a reduction in the amount of trained labels required for NLP tasks and more efficient training (both in time and cost) and increased accuracy of models. 

There are a number of potential challenges in applying these models in a digital humanities context. Firstly, pre-trained language models are trained on modern text, largely gathered from the Web. Secondly, these pre-trained language models are not trained on text produced as a result of OCR. This project aims to explore the impact of these two challenges. More specifically it would be suggested that the student explores the use of ULMFiT and BERT on classification and Named Entity Recognition tasks. This project would explore how well these models perform on historic texts with and without the use of fine tuning these models. Other NLP tasks and models could be explored depending on the students' interest. There are a range of outputs that could emerge from the project, including publications offering initial guidance for other researchers on the most effective approach to utilising these models for historic OCR text. The project uses data and benefits from experts from the [Living with Machines project](https://www.turing.ac.uk/research/research-projects/living-machines), based the [The Alan Turing Institute](https://www.turing.ac.uk) and the [British Library](https://www.bl.uk). 

#### Further reading:

Ruder, S. (2019). NLP's ImageNet moment has arrived. [online] Sebastian Ruder. Available at: http://ruder.io/nlp-imagenet.

‘An Embarrassingly Simple Approach for Transfer Learning from Pretrained Language Models’. GroundAI. https://www.groundai.com/project/an-embarrassingly-simple-approach-for-transfer-learning-from-pretrained-language-models/1.

Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. ‘BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding’. http://arxiv.org/abs/1810.04805.

Howard, Jeremy, and Sebastian Ruder. ‘Universal Language Model Fine-Tuning for Text Classification’. http://arxiv.org/abs/1801.06146.

Peters, Matthew E., Sebastian Ruder, and Noah A. Smith. ‘To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks’. http://arxiv.org/abs/1903.05987.

‘The 1st Workshop on Deep Learning Approaches for Low-Resource Natural Language Processing | ACL Member Portal’. https://www.aclweb.org/portal/content/1st-workshop-deep-learning-approaches-low-resource-natural-language-processing-1.

Yang, Yi, and Jacob Eisenstein. ‘Part-of-Speech Tagging for Historical English’. http://arxiv.org/abs/1603.03144.

###  Monitoring and explaining semantic variation with deep contextual embeddings

Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl), Kaspar Beelen and Kasra Hosseini (The Alan Turing Institute)

Words are malleable. In natural language, “meaning” is not permanently fixed, but tends to fluctuate as both the linguistic and historical contexts continuously change. This project focuses on algorithmic perspectives on semantic change, more specifically we scrutinize how recent advances language modelling help uncovering and understanding semantic variation (1) between social categories (such as political organisations) and (2) over time. The ability of neural networks to generate high-quality word representations has propelled deep learning to the centre of computational linguistics. In 2013, Mikolov (and colleagues) demonstrated how the vectors produced by a shallow neural network captured semantic and syntactic information of a word (Mikolov et al., 2013). Further research has shown that such vectors also capture historical (Hamilton et al., 2016), sociological (Garg et al., 2017) and ideological (Azarbonyad et al., 2017) aspects of language use.

Word2Vec and GloVe provide “static” word representations (i.e. they map each token to one vector), which clashes with the very context-sensitive dynamic of semantics. Only recently has a potential solution appeared on the horizon: the resurgence of (character-based) recurrent neural networks, has ushered in a shift towards “deep contextual” embeddings, which take into account the linguistic context to generate the representation of words and sentences (see ELMo (Peters et al., 2018) and BERT models (Devlin et al., 2018), for an overview see (Smith, 2019)). 

Given the recent innovations in the field of representation learning, this project investigates the use of (fine-tuned) contextual models for studying semantic variation -- taking both a sociological and historical approach. Data will consist of more than a century of historical newspapers (with extensive metadata, such as the places of circulation and the political leaning of the newspaper). This provides the ideal starting point for a fine-grained investigation, monitoring (and maybe even explaining) semantic change. The project uses data and benefits from experts from the [Living with Machines project](https://www.turing.ac.uk/research/research-projects/living-machines), based the [The Alan Turing Institute](https://www.turing.ac.uk) and the [British Library](https://www.bl.uk). 

#### Further Reading

Azarbonyad, Hosein, Mostafa Dehghani, Kaspar Beelen, Alexandra Arkut, Maarten Marx, and Jaap Kamps. "Words are malleable: Computing semantic shifts in political and media discourse." In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, pp. 1509-1518. ACM, 2017.

Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. "Bert: Pre-training of deep bidirectional transformers for language understanding." arXiv preprint arXiv:1810.04805 (2018).

Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. "Word embeddings quantify 100 years of gender and ethnic stereotypes." Proceedings of the National Academy of Sciences 115, no. 16 (2018): E3635-E3644.

Hamilton, William L., Jure Leskovec, and Dan Jurafsky. "Diachronic word embeddings reveal statistical laws of semantic change." arXiv preprint arXiv:1605.09096 (2016).

Jo, Eun Seo, and Mark Algee-Hewitt. "The Long Arc of History: Neural Network Approaches to Diachronic Linguistic Change." Journal of the Japanese Association for Digital Humanities 3, no. 1 (2018): 1-32.

Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. "Efficient estimation of word representations in vector space." arXiv preprint arXiv:1301.3781 (2013).

Peters, Matthew E., Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. "Deep contextualized word representations." arXiv preprint arXiv:1802.05365 (2018).

Smith, Noah A. "Contextual Word Representations: A Contextual Introduction." arXiv preprint arXiv:1902.06006 (2019).

###  More context, less bias? Social bias in deep contextual word representations 

Supervisor: [Giovanni Colavizza](mailto:g.colavizza@uva.nl) and Kaspar Beelen (The Alan Turing Institute)

Emasculated kings, injected with a decent portion of femininity, happen to become queens--or at least, this was one of the more sensational findings of Mikolov et al. 2013, who demonstrated that the geometric properties where useful analogical reasoning (i.e. king is to man as ?? is to woman, could be computed by vector(king) - vector(man) + vector(woman). Findings reported in a subsequent stream of papers pointed out how the vectors trained on a large amount of text produced by humans, were showing similar forms of stereotypes and biases (Caliskan et al., 2018; Garg et al., 2017).

Most of the models up to 2018, generated “static” vectors, mapping words (or character sequences) to a specific vector, ignoring that a word can be polysemous and that its meaning often depends on the context in which it is used (see Smith, 2019 for a more extensive overview). The latest generation of embeddings, however, are contextualized, they generate a vector for a word based on its sentential context. As contextual models grow in popularity, more pre-trained models are released (such as ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018,) among others). Even though the algorithms become increasingly complex, and the data on which that are trained continues to extend, the basic task remains one of language modelling, with humans telling computers what language should look like. For this reason, we investigate the extent to which these pre-trained models are prone to reproduce human-like biases, and what strategies could counter the potential effects on other downstream applications (Bolukbasi et al., 2016).

The project uses data and benefits from experts from the [Living with Machines project](https://www.turing.ac.uk/research/research-projects/living-machines), based the [The Alan Turing Institute](https://www.turing.ac.uk) and the [British Library](https://www.bl.uk). 

#### Further reading:

Bolukbasi, Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam T. Kalai. "Man is to computer programmer as woman is to homemaker? debiasing word embeddings." In Advances in neural information processing systems, pp. 4349-4357. 2016.

Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. "Semantics derived automatically from language corpora contain human-like biases." Science 356, no. 6334 (2017): 183-186.

Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. "Bert: Pre-training of deep bidirectional transformers for language understanding." arXiv preprint arXiv:1810.04805 (2018).

Hamilton, William L., Jure Leskovec, and Dan Jurafsky. "Diachronic word embeddings reveal statistical laws of semantic change." arXiv preprint arXiv:1605.09096 (2016).

Garg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. "Word embeddings quantify 100 years of gender and ethnic stereotypes." Proceedings of the National Academy of Sciences 115, no. 16 (2018): E3635-E3644.

Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. "Efficient estimation of word representations in vector space." arXiv preprint arXiv:1301.3781 (2013).

Peters, Matthew E., Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. "Deep contextualized word representations." arXiv preprint arXiv:1802.05365 (2018).

Smith, Noah A. "Contextual Word Representations: A Contextual Introduction." arXiv preprint arXiv:1902.06006 (2019).



### Efficient Neural NLP

Supervisors: [Jaap Kamps](mailto:kamps@uva.nl) ILLC


#### Description  

This is a project supported by Facebook Research and in collaboration with the University of Waterloo, Canada where we address efficiency aspects of neural NLP pipelines.   We have various researchers and student assistants working on this in the Netherlands and Canada, and have space for multiple students to get involved as MSc AI graduation project (up to four students).

#### References

Facebook AI, 2019.  Computationally Efficient Natural Language Processing request for proposals.   <https://research.fb.com/programs/research-awards/proposals/computationally-efficient-natural-language-processing-request-for-proposals/>.

Hamed Zamani, Mostafa Dehghani, W. Bruce Croft, Erik Learned-Miller, and Jaap Kamps. 2018. From Neural Re-Ranking to Neural Ranking: Learning a Sparse Representation for Inverted Indexing. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM '18). ACM, New York, NY, USA, 497-506. DOI: <https://doi.org/10.1145/3269206.3271800>.



### Who says What to Whom and Why?

Supervisors: [Jaap Kamps](mailto:kamps@uva.nl)  ILLC

#### Description:  

We have 200+ years of Parliamentary Proceedings for various countries, and have recent local city council proceedings from the Netherlands.   These are meeting notes typically verbatim transcriptions of spoken language.  We have extensive bibliographic data on most speakers (e.g., gender, date/place of birth, education level, etc) allowing for highly fine-grained analysis over various similarities and differences over demographics (e.g. gender, age, etc), over location (including representational systems in UK, Canada), or over time periods. We have space for multiple students to get involved as MSc AI graduation project (up to four students).


#### References

Political Mashup Projects, 2019.  <https://www.politicalmashup.nl>.

Search Engine/API, 2019.  <http://search.politicalmashup.nl/>.

Local city council data, 2019. <https://waaroverheid.nl>.

